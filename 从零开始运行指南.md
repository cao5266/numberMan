# DH_live 项目 - 从零开始运行指南

> 📖 这是一份详细的、面向小白的运行指南，将帮助您从零开始成功运行 DH_live 数字人项目。

## 📚 目录

1. [项目介绍](#项目介绍)
2. [准备工作](#准备工作)
3. [第一步：安装 Anaconda](#第一步安装-anaconda)
4. [第二步：下载项目](#第二步下载项目)
5. [第三步：创建 Python 环境](#第三步创建-python-环境)
6. [第四步：安装依赖包](#第四步安装依赖包)
7. [第五步：下载模型文件](#第五步下载模型文件)
8. [第六步：准备视频文件](#第六步准备视频文件)
9. [第七步：运行项目](#第七步运行项目)
10. [第八步：配置大模型（可选）](#第八步配置大模型可选)
11. [常见问题解决](#常见问题解决)

---

## 项目介绍

**DH_live** 是一个实时数字人直播系统，可以：
- 🎭 将您的视频转换为数字人
- 🗣️ 让数字人根据音频或文字说话
- 🌐 在网页上实时展示数字人
- 📱 支持手机、电脑等所有设备

**项目特点**：
- ✅ 无需训练，开箱即用
- ✅ 极低算力需求（39 Mflops）
- ✅ 支持 CPU 运行（无需 GPU）
- ✅ 网页资源仅 3MB

**项目地址**：https://github.com/kleinlee/DH_live

---

## 准备工作

### 您需要准备的东西：

1. ✅ **一台电脑**（Windows/Linux/macOS）
2. ✅ **网络连接**（下载依赖和模型）
3. ✅ **至少 5GB 的硬盘空间**
4. ✅ **一段视频文件**（MP4格式，建议5-30秒，人物正面，嘴巴不要动）

### 系统要求：

- **操作系统**：Windows 10/11、Linux、macOS
- **内存**：至少 4GB（推荐 8GB 以上）
- **CPU**：2核以上（推荐 4核）

---

## 第一步：安装 Anaconda

### 1.1 下载 Anaconda

1. 访问 Anaconda 官网：https://www.anaconda.com/products/distribution
2. 点击 "Download" 按钮
3. 选择适合您操作系统的版本（Windows/Mac/Linux）
4. 下载完成后，运行安装程序

### 1.2 安装 Anaconda

**Windows 用户**：
1. 双击下载的 `.exe` 文件
2. 按照安装向导操作
3. ✅ 重要：勾选 "Add Anaconda to my PATH environment variable"（如果出现此选项）
4. 点击 "Install" 开始安装
5. 等待安装完成

**Mac 用户**：
1. 双击下载的 `.pkg` 文件
2. 按照安装向导操作
3. 等待安装完成

**Linux 用户**：
```bash
# 下载安装脚本
wget https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh

# 运行安装脚本
bash Anaconda3-2024.02-1-Linux-x86_64.sh

# 按照提示操作，最后重启终端
```

### 1.3 验证安装

打开命令行（Windows 打开 "Anaconda Prompt"，Mac/Linux 打开终端），输入：

```bash
conda --version
```

如果显示版本号（如 `conda 23.7.4`），说明安装成功！

---

## 第二步：下载项目

### 方法一：使用 Git 克隆（推荐）

1. 打开命令行（Anaconda Prompt 或终端）

2. 进入您想要存放项目的目录，例如：
   ```bash
   # Windows
   cd D:\work
   
   # Mac/Linux
   cd ~/workspace
   ```

3. 克隆项目：
   ```bash
   git clone https://github.com/kleinlee/DH_live.git
   ```

4. 进入项目目录：
   ```bash
   cd DH_live
   ```

### 方法二：直接下载 ZIP 文件

1. 访问项目地址：https://github.com/kleinlee/DH_live
2. 点击绿色的 "Code" 按钮
3. 选择 "Download ZIP"
4. 解压下载的 ZIP 文件
5. 进入解压后的文件夹

---

## 第三步：创建 Python 环境

### 3.1 打开 Anaconda Prompt

**Windows 用户**：
- 在开始菜单搜索 "Anaconda Prompt"，点击打开

**Mac/Linux 用户**：
- 打开终端（Terminal）

### 3.2 创建虚拟环境

在命令行中执行以下命令：

```bash
# 创建名为 dh_live 的虚拟环境，使用 Python 3.11
conda create -n dh_live python=3.11

# 当提示是否继续时，输入 y 并按回车
```

**重要提示**：
- ⚠️ Python 版本必须是 3.8-3.11（推荐 3.11）
- ⚠️ 不要使用 Python 3.12 或更高版本（mediapipe 不支持）

### 3.3 激活虚拟环境

```bash
# 激活环境
conda activate dh_live

# 验证 Python 版本
python --version
```

您应该看到类似 `Python 3.11.x` 的输出。

**提示**：每次使用项目前，都需要先激活环境：
```bash
conda activate dh_live
```

---

## 第四步：安装依赖包

### 4.1 进入项目目录

确保您在项目根目录（包含 `requirements.txt` 文件的目录）：

```bash
# 如果还没有进入项目目录，先进入
cd DH_live

# 验证是否在正确的目录
ls requirements.txt  # Mac/Linux
dir requirements.txt  # Windows
```

### 4.2 安装 PyTorch

**如果您有 NVIDIA GPU**（可选，但推荐）：
```bash
pip install torch --index-url https://download.pytorch.org/whl/cu124
```

**如果您没有 GPU 或使用 CPU**：
```bash
pip install torch
```

### 4.3 安装其他依赖

```bash
# 安装所有依赖包
pip install -r requirements.txt
```

**如果下载很慢**，可以使用国内镜像：
```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 4.4 验证安装

等待安装完成后，验证关键包是否安装成功：

```bash
python -c "import torch; print('PyTorch:', torch.__version__)"
python -c "import gradio; print('Gradio: OK')"
python -c "import mediapipe; print('Mediapipe: OK')"
```

如果都显示正常，说明依赖安装成功！

---

## 第五步：下载模型文件

### 5.1 创建 checkpoint 目录

在项目根目录下创建 `checkpoint` 文件夹：

```bash
# Windows
mkdir checkpoint
mkdir checkpoint\lstm
mkdir checkpoint\DINet_mini

# Mac/Linux
mkdir -p checkpoint/lstm
mkdir -p checkpoint/DINet_mini
```

### 5.2 下载模型文件

模型文件比较大，需要从网盘下载：

**下载地址**：
- **百度网盘**：https://pan.baidu.com/s/1jH3WrIAfwI3U5awtnt9KPQ?pwd=ynd7
- **Google Drive**：https://drive.google.com/drive/folders/1az5WEWOFmh0_yrF3I9DEyctMyjPolo8V?usp=sharing

**需要下载的文件**：
1. `lstm_model_epoch_325.pkl` → 放到 `checkpoint/lstm/` 目录
2. `epoch_40.pth` → 放到 `checkpoint/DINet_mini/` 目录

**目录结构应该是这样**：
```
checkpoint/
├── lstm/
│   └── lstm_model_epoch_325.pkl
└── DINet_mini/
    └── epoch_40.pth
```

### 5.3 验证模型文件

```bash
# Windows
dir checkpoint\lstm\lstm_model_epoch_325.pkl
dir checkpoint\DINet_mini\epoch_40.pth

# Mac/Linux
ls checkpoint/lstm/lstm_model_epoch_325.pkl
ls checkpoint/DINet_mini/epoch_40.pth
```

如果文件存在，说明模型下载成功！

---

## 第六步：准备视频文件

### 6.1 视频要求

**视频要求**：
- ✅ 格式：MP4
- ✅ 时长：5-30秒
- ✅ 内容：人物正面，嘴巴不要动（保持闭嘴或微张）
- ✅ 分辨率：任意（会自动处理）
- ⚠️ **重要**：嘴巴如果有动作会影响效果，请认真对待

### 6.2 准备视频

1. 将您的视频文件放到 `video_data` 目录下
2. 创建一个子文件夹，例如 `video_data/my_video/`
3. 将视频文件重命名为 `video.mp4`
4. 最终路径应该是：`video_data/my_video/video.mp4`

**示例**：
```
video_data/
└── my_video/
    └── video.mp4
```

---

## 第七步：运行项目

### 方式一：使用 Gradio 界面（推荐新手）

Gradio 提供了一个图形界面，可以方便地处理视频和生成数字人。

#### 7.1 启动 Gradio

在项目根目录下执行：

```bash
# 确保已经激活环境
conda activate dh_live

# 进入项目目录
cd DH_live

# 启动 Gradio
python app.py
```

#### 7.2 使用 Gradio 界面

1. 等待程序启动（可能需要几十秒）
2. 浏览器会自动打开，或者手动访问：http://127.0.0.1:7860
3. 在界面上：
   - **第一部分**：上传您的视频文件，点击"处理视频"
   - **第二部分**：上传音频文件（可选），点击"生成视频"
   - **第三部分**：点击"启动网页"，启动 Web 服务

#### 7.3 访问网页界面

启动网页后，访问：http://localhost:8888/static/MiniLive.html

---

### 方式二：使用命令行（高级用户）

#### 7.1 处理视频

```bash
# 处理视频（替换路径为您自己的视频路径）
python data_preparation_mini.py video_data/my_video/video.mp4 video_data/my_video

# 准备网页资源
python data_preparation_web.py video_data/my_video
```

#### 7.2 生成视频（可选，仅 Windows 支持）

```bash
# 使用音频文件生成视频
python demo_mini.py video_data/my_video/assets video_data/audio0.wav output.mp4
```

#### 7.3 启动 Web 服务

```bash
# 启动简单演示服务
python web_demo/server.py

# 或者启动实时语音对话服务（需要配置大模型）
python web_demo/server_realtime.py
```

然后访问：http://localhost:8888/static/MiniLive.html

---

## 第八步：配置大模型（可选）

如果您想让数字人能够进行真实的对话，需要配置大模型 API。

### 8.1 获取 API Key

支持的大模型服务：
1. **DeepSeek**（推荐）：https://www.deepseek.com/
2. **豆包**（字节跳动）：https://www.volcengine.com/product/ark
3. **OpenAI**：https://platform.openai.com/

### 8.2 配置 API

1. 打开文件：`web_demo/voiceapi/llm.py`

2. 编辑配置，例如使用 DeepSeek：
   ```python
   from openai import OpenAI
   # DeepSeek
   base_url = "https://api.deepseek.com"
   api_key = "您的API密钥"  # 替换为您的实际 API 密钥
   model_name = "deepseek-chat"
   
   llm_client = OpenAI(
       base_url=base_url,
       api_key=api_key,
   )
   ```

3. 保存文件

### 8.3 下载 TTS 模型（可选，用于真实语音合成）

如果需要真实语音合成，需要下载 TTS 模型：

1. 创建 `models` 目录：
   ```bash
   mkdir models
   ```

2. 下载 TTS 模型：
   - 下载地址：https://github.com/k2-fsa/sherpa-onnx/releases/download/tts-models/sherpa-onnx-vits-zh-ll.tar.bz2
   - 解压到 `models/` 目录

3. 目录结构：
   ```
   models/
   └── sherpa-onnx-vits-zh-ll/
       ├── model.onnx
       ├── lexicon.txt
       ├── tokens.txt
       └── dict/
   ```

### 8.4 启动实时对话服务

```bash
# 启动实时语音对话服务
python web_demo/server_realtime.py
```

访问：http://localhost:8888/static/MiniLive_RealTime.html

---

## 常见问题解决

### 问题1：mediapipe 安装失败

**错误信息**：`ERROR: No matching distribution found for mediapipe`

**解决方案**：
1. 确保 Python 版本是 3.8-3.11
2. 单独安装 mediapipe：
   ```bash
   pip install mediapipe==0.10.9
   ```

### 问题2：找不到模型文件

**错误信息**：`FileNotFoundError: [Errno 2] No such file or directory`

**解决方案**：
1. 检查 `checkpoint` 目录是否存在
2. 检查模型文件是否下载完整
3. 确认文件路径正确

### 问题3：Gradio 启动失败

**错误信息**：`ImportError: cannot import name 'HfFolder'`

**解决方案**：
```bash
pip install --upgrade gradio
pip install "huggingface_hub<0.20.0"
```

### 问题4：端口被占用

**错误信息**：`Address already in use`

**解决方案**：
1. 关闭占用 8888 端口的其他程序
2. 或者修改端口：
   ```bash
   # 修改 server.py 中的端口号
   uvicorn.run(app, host="0.0.0.0", port=8889)
   ```

### 问题5：视频处理失败

**可能原因**：
1. 视频格式不支持
2. 视频文件损坏
3. 视频中没有检测到人脸

**解决方案**：
1. 确保视频是 MP4 格式
2. 确保视频中有人脸（正面）
3. 尝试使用其他视频文件

### 问题6：大模型调用失败

**错误信息**：`AssertionError: 您必须配置自己的LLM API秘钥`

**解决方案**：
1. 检查 `web_demo/voiceapi/llm.py` 中的 API 密钥是否正确
2. 确保 API 密钥有效且未过期
3. 检查网络连接

---

## 快速开始 Checklist

使用这个清单来检查您的进度：

- [ ] ✅ 安装 Anaconda
- [ ] ✅ 下载项目
- [ ] ✅ 创建 Python 环境（Python 3.11）
- [ ] ✅ 激活环境
- [ ] ✅ 安装 PyTorch
- [ ] ✅ 安装依赖包
- [ ] ✅ 下载模型文件
- [ ] ✅ 准备视频文件
- [ ] ✅ 运行 `python app.py`
- [ ] ✅ 在浏览器中打开 Gradio 界面
- [ ] ✅ 处理视频
- [ ] ✅ 启动网页服务
- [ ] ✅ 访问网页查看数字人
- [ ] ⭕ （可选）配置大模型 API
- [ ] ⭕ （可选）下载 TTS 模型
- [ ] ⭕ （可选）启动实时对话服务

---

## 下一步

### 1. 更换数字人形象

将新处理的视频的 `assets` 文件夹内容复制到 `web_demo/static/assets/` 目录。

### 2. 自定义对话

修改 `web_demo/voiceapi/llm.py` 中的系统提示词，改变数字人的角色和性格。

### 3. 部署到服务器

将项目部署到服务器，让其他人也能访问您的数字人。

### 4. 商业授权

如果需要商业使用且去除 logo，访问：www.matesx.com/authorized.html

---

## 获取帮助

### 官方资源

- **项目地址**：https://github.com/kleinlee/DH_live
- **在线演示**：https://matesx.com
- **小程序**：搜索 "MatesX数字生命"

### 社区支持

- **GitHub Issues**：https://github.com/kleinlee/DH_live/issues
- **微信群**：查看项目 README 中的二维码
- **QQ群**：查看项目 README 中的二维码

---

## 总结

恭喜您！现在您已经学会了如何从零开始运行 DH_live 项目。

**记住几个关键步骤**：
1. 安装 Anaconda 和 Python 环境
2. 安装依赖包
3. 下载模型文件
4. 准备视频文件
5. 运行 `python app.py`

如果遇到问题，请参考"常见问题解决"部分，或访问项目 GitHub 页面获取帮助。

祝您使用愉快！🎉

---

**文档版本**：v1.0  
**最后更新**：2025-01-XX  
**项目版本**：基于 DH_live main 分支

